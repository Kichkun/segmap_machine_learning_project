{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.5751 - reconstruction_output_loss: 0.0693 - classification_output_loss: -0.2877\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 13.5612 - reconstruction_output_loss: 0.0692 - classification_output_loss: -0.2877\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 13.5468 - reconstruction_output_loss: 0.0692 - classification_output_loss: -0.2877\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 13.5323 - reconstruction_output_loss: 0.0691 - classification_output_loss: -0.2877\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 13.5179 - reconstruction_output_loss: 0.0690 - classification_output_loss: -0.2877\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 13.5033 - reconstruction_output_loss: 0.0690 - classification_output_loss: -0.2877\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 13.4888 - reconstruction_output_loss: 0.0689 - classification_output_loss: -0.2877\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 13.4742 - reconstruction_output_loss: 0.0688 - classification_output_loss: -0.2877\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 13.4596 - reconstruction_output_loss: 0.0687 - classification_output_loss: -0.2877\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 13.4451 - reconstruction_output_loss: 0.0687 - classification_output_loss: -0.2877\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 13.4301 - reconstruction_output_loss: 0.0686 - classification_output_loss: -0.2877\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 13.4154 - reconstruction_output_loss: 0.0685 - classification_output_loss: -0.2877\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 13.4008 - reconstruction_output_loss: 0.0684 - classification_output_loss: -0.2877\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 13.3859 - reconstruction_output_loss: 0.0684 - classification_output_loss: -0.2877\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 13.3713 - reconstruction_output_loss: 0.0683 - classification_output_loss: -0.2877\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 13.3566 - reconstruction_output_loss: 0.0682 - classification_output_loss: -0.2877\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 13.3416 - reconstruction_output_loss: 0.0681 - classification_output_loss: -0.2877\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 13.3269 - reconstruction_output_loss: 0.0681 - classification_output_loss: -0.2877\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 13.3123 - reconstruction_output_loss: 0.0680 - classification_output_loss: -0.2877\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 13.2973 - reconstruction_output_loss: 0.0679 - classification_output_loss: -0.2877\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 13.2826 - reconstruction_output_loss: 0.0679 - classification_output_loss: -0.2877\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 13.2677 - reconstruction_output_loss: 0.0678 - classification_output_loss: -0.2877\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 13.2530 - reconstruction_output_loss: 0.0677 - classification_output_loss: -0.2877\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 13.2382 - reconstruction_output_loss: 0.0676 - classification_output_loss: -0.2877\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 13.2233 - reconstruction_output_loss: 0.0676 - classification_output_loss: -0.2877\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 13.2087 - reconstruction_output_loss: 0.0675 - classification_output_loss: -0.2877\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 13.1936 - reconstruction_output_loss: 0.0674 - classification_output_loss: -0.2877\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 13.1790 - reconstruction_output_loss: 0.0673 - classification_output_loss: -0.2877\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 13.1643 - reconstruction_output_loss: 0.0673 - classification_output_loss: -0.2877\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 13.1493 - reconstruction_output_loss: 0.0672 - classification_output_loss: -0.2877\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 13.1346 - reconstruction_output_loss: 0.0671 - classification_output_loss: -0.2877\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 13.1197 - reconstruction_output_loss: 0.0670 - classification_output_loss: -0.2877\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 13.1050 - reconstruction_output_loss: 0.0670 - classification_output_loss: -0.2877\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 13.0903 - reconstruction_output_loss: 0.0669 - classification_output_loss: -0.2877\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 13.0754 - reconstruction_output_loss: 0.0668 - classification_output_loss: -0.2877\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 13.0607 - reconstruction_output_loss: 0.0667 - classification_output_loss: -0.2877\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 13.0460 - reconstruction_output_loss: 0.0667 - classification_output_loss: -0.2877\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 13.0310 - reconstruction_output_loss: 0.0666 - classification_output_loss: -0.2877\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 13.0164 - reconstruction_output_loss: 0.0665 - classification_output_loss: -0.2877\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 13.0017 - reconstruction_output_loss: 0.0664 - classification_output_loss: -0.2877\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 12.9868 - reconstruction_output_loss: 0.0664 - classification_output_loss: -0.2877\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 12.9722 - reconstruction_output_loss: 0.0663 - classification_output_loss: -0.2877\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 12.9571 - reconstruction_output_loss: 0.0662 - classification_output_loss: -0.2877\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 12.9425 - reconstruction_output_loss: 0.0662 - classification_output_loss: -0.2877\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 12.9279 - reconstruction_output_loss: 0.0661 - classification_output_loss: -0.2877\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 12.9132 - reconstruction_output_loss: 0.0660 - classification_output_loss: -0.2877\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 12.8983 - reconstruction_output_loss: 0.0659 - classification_output_loss: -0.2877\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 12.8837 - reconstruction_output_loss: 0.0659 - classification_output_loss: -0.2877\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 12.8690 - reconstruction_output_loss: 0.0658 - classification_output_loss: -0.2877\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 12.8541 - reconstruction_output_loss: 0.0657 - classification_output_loss: -0.2877\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Layer, Input, Dense, Conv3D, MaxPooling3D, UpSampling3D, Dropout, Flatten,InputLayer , Reshape, concatenate, Concatenate, Activation\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "        \n",
    "input_voxel = Input(shape=(32, 32, 16, 1))\n",
    "scales = Input(shape=(1, 3))\n",
    "\n",
    "# Convolution\n",
    "x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(input_voxel)\n",
    "x = MaxPooling3D((2, 2, 2), padding='same')(x)\n",
    "x = Conv3D(64, (3, 3 ,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D((2, 2, 2), padding='same')(x)\n",
    "x = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Reshape((1, 16384))(x)\n",
    "x = Concatenate()([x, scales])\n",
    "\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Descriptor\n",
    "description = Dense(64)(x)\n",
    "\n",
    "# Deconvolution\n",
    "x = Dense(8192)(description)\n",
    "x = Reshape((8, 8, 4, 32))(x)\n",
    "x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling3D((2, 2, 2))(x)\n",
    "x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling3D((2, 2, 2))(x)\n",
    "reconstructed = Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='reconstruction_output')(x)\n",
    "\n",
    "#Classificator\n",
    "y = BatchNormalization()(description)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense(4)(y)\n",
    "classified = Activation('softmax', name='classification_output')(y)\n",
    "\n",
    "def reconstruction_loss(voxels, reconstructed):\n",
    "    FN_TO_FP_WEIGHT = 0.9\n",
    "    loss_r = - tf.math.reduce_mean(FN_TO_FP_WEIGHT * voxels * keras.backend.log(reconstructed + 1e-10) + (1 - FN_TO_FP_WEIGHT) * \\\n",
    "                            (1 - voxels) * keras.backend.log(1 - reconstructed + 1e-10))\n",
    "    return loss_r\n",
    "\n",
    "def classification_loss(classes, classified):\n",
    "    loss_c = -tf.math.reduce_mean(keras.losses.binary_crossentropy(classes, classified))\n",
    "    return loss_c\n",
    "\n",
    "losses = {\n",
    "\t\"reconstruction_output\": reconstruction_loss,\n",
    "\t\"classification_output\": classification_loss\n",
    "}\n",
    "loss_weights = {\"reconstruction_output\": 200, \"classification_output\": 1}\n",
    "\n",
    "autoencoder = Model(inputs=[input_voxel, scales], outputs=[reconstructed, classified])\n",
    "autoencoder.compile(optimizer='adadelta', loss=losses, loss_weights=loss_weights)\n",
    "\n",
    "history = autoencoder.fit(x=[np.zeros((1, 32, 32, 16, 1)), np.zeros((1, 1, 3))], \n",
    "                          y=[np.zeros((1, 32, 32, 16, 1)), np.zeros((1, 1, 4))], \n",
    "                          epochs=50, batch_size=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 1, 'epochs': 50, 'steps': None, 'samples': 1, 'verbose': 1, 'do_validation': False, 'metrics': ['loss', 'reconstruction_output_loss', 'classification_output_loss']}\n",
      "[13.575098037719727, 13.56118392944336, 13.546806335449219, 13.53233528137207, 13.517911911010742, 13.503253936767578, 13.488819122314453, 13.47421646118164, 13.459611892700195, 13.44505500793457, 13.43010139465332, 13.415407180786133, 13.400838851928711, 13.385860443115234, 13.371288299560547, 13.356586456298828, 13.341602325439453, 13.326906204223633, 13.312309265136719, 13.29725456237793, 13.282621383666992, 13.267688751220703, 13.252969741821289, 13.238248825073242, 13.223312377929688, 13.208681106567383, 13.193626403808594, 13.179018020629883, 13.164321899414062, 13.149251937866211, 13.134624481201172, 13.119680404663086, 13.104965209960938, 13.090274810791016, 13.075395584106445, 13.06070327758789, 13.04599380493164, 13.031042098999023, 13.016422271728516, 13.001737594604492, 12.98678207397461, 12.97216796875, 12.95712661743164, 12.942527770996094, 12.92791748046875, 12.913238525390625, 12.898284912109375, 12.883695602416992, 12.869024276733398, 12.854135513305664]\n"
     ]
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
